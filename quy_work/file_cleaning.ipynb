{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5cd18c",
   "metadata": {},
   "source": [
    "# Patient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully written to ./Output/jsons/Demographics.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "csv_file_path = '../data/Demographics.csv'\n",
    "output_dir = './Output/jsons/'\n",
    "output_file_path = os.path.join(output_dir, 'Demographics.json')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "data_json = df.to_dict(orient='records')\n",
    "\n",
    "# Write the JSON object to a file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(data_json, json_file, indent=4)\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dcf6b3",
   "metadata": {},
   "source": [
    "# Glucose Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35af210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input file and output directory\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the dictionary to store the data\n",
    "data_dict = {}\n",
    "\n",
    "#traverse teh data directory to find the Dexcom CSV file\n",
    "input_file_dir = {}\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.startswith(\"Dexcom\"):\n",
    "            # get name of directory file is in\n",
    "            dir_name = os.path.basename(root)\n",
    "\n",
    "            input_file_dir[dir_name] = os.path.join(root, file)\n",
    "            break  # Stop after finding the first Dexcom file in directory\n",
    "\n",
    "# read each Dexcom file and append the data to the dictionary\n",
    "for key, value in input_file_dir.items():\n",
    "    # Load the full CSV\n",
    "    df = pd.read_csv(value)\n",
    "\n",
    "    # Filter for glucose events (Event Type == 'EGV')\n",
    "    df_egv = df[df['Event Type'] == 'EGV'].copy()\n",
    "\n",
    "    # Convert timestamp to datetime format\n",
    "    df_egv['Timestamp (YYYY-MM-DDThh:mm:ss)'] = pd.to_datetime(df_egv['Timestamp (YYYY-MM-DDThh:mm:ss)'])\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df_egv.rename(columns={\n",
    "        'Timestamp (YYYY-MM-DDThh:mm:ss)': 'timestamp',\n",
    "        'Glucose Value (mg/dL)': 'glucose',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    df_egv = df_egv[['timestamp', 'glucose']].reset_index(drop=True)\n",
    "\n",
    "    # Convert timestamp to ISO format\n",
    "    df_egv['timestamp'] = df_egv['timestamp'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Convert Datafrsame to dictionary\n",
    "    data_dict[key] = df_egv.to_dict(orient='records')\n",
    "\n",
    "# Write the data to a JSON file\n",
    "output_file_path = os.path.join(output_dir, 'glucose.json')\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(data_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da019229",
   "metadata": {},
   "source": [
    "# Prelim Food_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6842b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "002\n",
      "004\n",
      "005\n",
      "006\n",
      "007\n",
      "008\n",
      "009\n",
      "010\n",
      "011\n",
      "012\n",
      "013\n",
      "014\n",
      "015\n",
      "016\n"
     ]
    }
   ],
   "source": [
    "# Define the input file and output directory\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the list to store the data\n",
    "data_list = []\n",
    "\n",
    "#traverse teh data directory to find the Dexcom CSV file\n",
    "input_file_dir = {}\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.startswith(\"Food_Log\"):\n",
    "            # get name of directory file is in\n",
    "            dir_name = os.path.basename(root)\n",
    "\n",
    "            input_file_dir[dir_name] = os.path.join(root, file)\n",
    "            break  # Stop after finding the first Dexcom file in directory\n",
    "\n",
    "\n",
    "# read each Dexcom file and append the data to the dictionary\n",
    "for key, value in input_file_dir.items():\n",
    "\n",
    "    if key == \"003\":\n",
    "        # Skip the first file\n",
    "        continue\n",
    "\n",
    "    print(key)\n",
    "    # Load the CSV file\n",
    "    df_food_log = pd.read_csv(value)\n",
    "\n",
    "    # Combine 'date' and 'time' into a single datetime column\n",
    "    df_food_log['datetime'] = pd.to_datetime(df_food_log['date'] + ' ' + df_food_log['time'])\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = ['datetime'] + [col for col in df_food_log.columns if col != 'datetime']\n",
    "    df_food_log = df_food_log[cols]\n",
    "\n",
    "    # Convert nutrition columns to numeric\n",
    "    numeric_cols = ['calorie', 'total_carb', 'dietary_fiber', 'sugar', 'protein', 'total_fat']\n",
    "    df_food_log[numeric_cols] = df_food_log[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # add coloumn for patiendent ID\n",
    "    df_food_log['ID'] = key\n",
    "\n",
    "    #add empty columns for tags\n",
    "    df_food_log['tags'] = \"\"\n",
    "\n",
    "\n",
    "    # Convert timestamp to ISO format\n",
    "    df_food_log['datetime'] = df_food_log['datetime'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Convert Datafrsame to dictionary\n",
    "    data_list.extend(df_food_log.to_dict(orient='records'))\n",
    "\n",
    "#save the data to a JSON file\n",
    "output_file_path = os.path.join(output_dir, 'food_log.json')\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(data_list, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93355cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Balance Smart Balance\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "output_dir = './Output/jsons/'\n",
    "\n",
    "input_file_path = os.path.join(output_dir, 'food_log.json')\n",
    "output_file_path = os.path.join(output_dir, 'food_log_tagged.json')\n",
    "\n",
    "# Load your JSON data (replace with your file path or variable)\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Tag definitions\n",
    "tag_keywords = {\n",
    "    'meat': [\n",
    "        'chicken', 'beef', 'pork', 'turkey', 'sausage', 'bacon', 'ham', 'rib', 'steak', 'chorizo', 'nugget', 'slider', 'wings', 'jerky',\n",
    "        'pepperoni', 'lamb', 'salami', 'duck', 'lamb gyro', 'duck burrito', 'duck soup with dumpling'\n",
    "    ],\n",
    "    'seafood': [\n",
    "        'anchovies', 'fish', 'salmon', 'shrimp', 'crab', 'tuna', 'seafood', 'sardines', 'squid', 'octopus', 'shellfish', 'lobster', 'scallops',\n",
    "        'tilapia', 'sushi', 'california roll'\n",
    "    ],\n",
    "    'drink': [\n",
    "        'coca cola', 'beer', 'lemonade', 'boost', 'water', 'soda', 'coffee', 'tea', 'juice', 'milk', 'smoothie', 'shake', 'gatorade', 'powerade',\n",
    "        'chocolate milk', 'hot chocolate', 'chai', 'sweet tea', 'mello yello', 'mountain dew', 'frozen pop', 'premier protein', 'protein shake',\n",
    "        'moscato', 'corona', 'mojito', 'chardonnay wine', 'diet coke', 'diet pepsi', 'coke', 'vodka', 'red wine', 'latte', 'decaf latte', 'skim decaf latte',\n",
    "        'jim beam bourbon', 'gray goose', 'grey goose', 'pepsi', 'diet pepsi', 'diet dr pepper', 'dr pepper', 'sweet tea', 'sweet tea vodka',\n",
    "        'sweet tea with lemonade', 'sweet tea with vodka', 'sweet tea with sweet tea vodka', 'sweet tea with sweet tea and lemonade', 'sweet tea with sweet tea and vodka',\n",
    "        'whey protein', 'v8', 'v8 juice', 'v8 splash', 'v8 energy', 'v8 energy drink', 'v8 energy juice', 'v8 energy smoothie', 'v8 energy shake',\n",
    "    ],\n",
    "    'entree': [\n",
    "        'sloppy joe', 'burritos', 'salad', 'wrap', 'bowl', 'sandwich', 'burger', 'pizza', 'mac and cheese', 'ziti', 'sub', 'taco', 'baked chicken',\n",
    "        'chicken and rice', 'chicken breast', 'chicken thigh', 'chicken wing', 'chicken leg', 'chicken biscuit', 'chicken chorizo', 'chicken nuggets',\n",
    "        'omelet', 'egg salad', 'baked potato', 'salisbury steak', 'pot pie', 'ravioli', 'taco salad', 'chipotle', 'deluxe cheeseburger macaroni',\n",
    "        'cheeseburger', 'roast beef', 'baked cheetos', 'totinos pizza', 'lean cuisine', 'lasagna', 'vegetable lasagna', 'stuffing', 'brunswick stew', 'soup'\n",
    "    ],\n",
    "    'snack': [\n",
    "        'fries', 'chips', 'chip', 'trail mix', 'popcorn', 'cookie', 'cookies', 'crackers', 'granola', 'bar', 'jerky', 'muffin', 'nutrigrain', 'fritos',\n",
    "        'chex mix', 'tootsie', 'oreo', 'fig newton', 'fig bar', 'fruit bar', 'biscotti', 'biscott', 'snickers', 'baby ruth', 'ritz', 'cheetos', 'pistachios',\n",
    "        'multigrain', 'blue bunny', 'fruit bars', 'string beans', 'grits', 'grapes', 'mandarin', 'tangerine', 'banana bread', 'salsa', 'hummus', 'peanut butter',\n",
    "        'peppers', 'onions', 'spinach', 'asparagus', 'cabbage', 'rice', 'beans', 'black beans', 'green bean', 'green beans', 'squash', 'corn flakes', 'cornflakes',\n",
    "        'frosted flakes', 'cereal', 'pita', 'pita bread', 'babybel', 'cheese stick', 'cheese', 'creamers', 'creamer', 'sugar', 'm&ms', 'fruit smoothie',\n",
    "        'pb protein whey powder', 'blueberries', 'strawberries', 'lemon loaf', 'lemon risotto', 'apple', 'peach', 'orange', 'navel orange', 'townhouse cracker',\n",
    "        'mini croissants', 'pecan twirl', 'donut', 'hershey kiss', 'pretzel rod', 'mixed nuts', 'cashew nut', 'walnut', 'pecans', 'almonds', 'toffee', 'lifesavers',\n",
    "        'lifesaver', 'andes creme de menthe', 'sathers caramel creams', 'goetzes caramel cremes', 'peanut m & m', 'm&m\\'s', 'sweetner', 'equal', 'stevia', 'honey',\n",
    "        'raisins', 'gin soaked raisins', 'angel food candy', 'frosted flake', 'sweet potato', 'small sweet potato', 'baked sweet potato', 'thin mints', 'thin mint',\n",
    "        'mozarrella sticks', 'grape', 'tatziki', 'candy', 'kashi', 'peanut', 'clementine', 'clementines', 'pear', 'grapefruit', 'grapefruits', 'kiwi',\n",
    "        'kiwis', 'fruit', 'berries', 'berry', 'fruit salad', 'fruit cup', 'fruit cocktail', 'fruit snacks', 'fruit roll up', 'fruit leather', 'fruit smoothie',\n",
    "    ],\n",
    "    'dessert': [\n",
    "        'cake', 'ice cream', 'oreo', 'fig newton', 'fig bar', 'fruit bar', 'biscotti', 'biscott', 'snickers', 'baby ruth', 'ritz', 'cheesecake', 'blue bunny',\n",
    "        'chocolate', 'tootsie', 'm&ms', 'banana bread', 'lemon loaf', 'fudge', 'cookie', 'cookies', 'brownie', 'pancake', 'waffle', 'cinnamon raisin bagel',\n",
    "        'muffin', 'pop', 'frozen pop', 'fruit bars', 'nutrigrain', 'granola bar', 'pecan twirl', 'donut', 'hershey kiss', 'toffee', 'angel food candy', 'syrup'\n",
    "    ],\n",
    "    'vegetarian': [\n",
    "        'butter', 'cheese', 'egg', 'eggs', 'milk', 'yogurt', 'pita', 'pita bread', 'cereal', 'corn flakes', 'cornflakes', 'frosted flakes', 'granola', 'bar',\n",
    "        'muffin', 'nutrigrain', 'fritos', 'chex mix', 'tootsie', 'oreo', 'fig newton', 'fig bar', 'fruit bar', 'biscotti', 'biscott', 'snickers', 'baby ruth',\n",
    "        'ritz', 'cheetos', 'pistachios', 'multigrain', 'blue bunny', 'fruit bars', 'string beans', 'grits', 'grapes', 'mandarin', 'tangerine', 'banana bread',\n",
    "        'salsa', 'hummus', 'peanut butter', 'peppers', 'onions', 'spinach', 'asparagus', 'cabbage', 'rice', 'beans', 'black beans', 'green bean', 'green beans',\n",
    "        'squash', 'apple', 'peach', 'orange', 'navel orange', 'salad', 'waffle', 'pancake', 'cake', 'ice cream', 'chocolate', 'fudge', 'cookies', 'cookie',\n",
    "        'brownie', 'lemon loaf', 'lemon risotto', 'avocado', 'flaxseed', 'psyllium husks', 'cinnamon', 'extra virgin olive oil', 'olive oil', 'balsamic vinegar',\n",
    "        'lettuce mix', 'tomatoes', 'beets', 'carrots', 'cucumber', 'red bell pepper', 'brussel sprouts', 'almond nut thins', 'sweet potato', 'stuffing', 'oatmeal',\n",
    "        'half and half', 'half and half', 'creamer', 'creamers', 'sugar', 'sweetner', 'equal', 'stevia', 'honey', 'raisins', 'gin soaked raisins','mozzarella',\n",
    "        'corn', 'tortilla', 'bean',  'smart balance'\n",
    "    ],\n",
    "    'vegan': [\n",
    "        'fries', 'onion', 'celery', 'bread', 'potatoes', 'peas', 'rice', 'beans', 'black beans', 'green bean', 'green beans', 'squash', 'apple', 'mandarin',\n",
    "        'tangerine', 'peach', 'orange', 'navel orange', 'salad', 'asparagus', 'cabbage', 'spinach', 'peppers', 'onions', 'grapes', 'banana', 'trail mix',\n",
    "        'popcorn', 'pistachios', 'multigrain', 'hummus', 'avocado', 'flaxseed', 'psyllium husks', 'cinnamon', 'extra virgin olive oil', 'olive oil', 'balsamic vinegar',\n",
    "        'lettuce mix', 'tomatoes', 'beets', 'carrots', 'cucumber', 'red bell pepper', 'brussel sprouts', 'sweet potato', 'faro', 'raisins', 'potato', 'olives', 'pear',\n",
    "        'grape', 'lemon', 'vegetable', 'vegetables', 'vegetable soup', 'vegetable broth', 'vegetable stir fry', 'vegetable curry', 'vegetable lasagna', 'vegetable fried rice',\n",
    "        'peanut', 'clementine', 'clementines', 'kiwi', 'kiwis', 'fruit', 'berries', 'berry', 'fruit salad', 'fruit cup', 'fruit cocktail', 'fruit snacks',\n",
    "    ],\n",
    "    'breakfast': [\n",
    "        'egg', 'eggs', 'omelet', 'cereal', 'corn flakes', 'cornflakes', 'frosted flakes', 'muffin', 'pancake', 'waffle', 'biscuit', 'bacon', 'sausage', 'grits',\n",
    "        'breakfast', 'trail mix', 'yogurt', 'banana bread', 'granola bar', 'nutrigrain', 'toast', 'coffee', 'milk', 'juice', 'oatmeal', 'bagel', 'plain bagel',\n",
    "        'std bfast','quaker', 'tater tot'\n",
    "    ],\n",
    "    'lunch': [\n",
    "        'burritos', 'wrap', 'sub', 'sandwich', 'bowl', 'salad', 'chicken nuggets', 'chicken wrap', 'chicken salad', 'chicken and rice', 'chicken breast',\n",
    "        'chicken thigh', 'chicken wing', 'chicken leg', 'chicken biscuit', 'chicken chorizo', 'omelet', 'egg salad', 'baked potato', 'salisbury steak', 'pot pie',\n",
    "        'ravioli', 'taco salad', 'chipotle', 'deluxe cheeseburger macaroni', 'cheeseburger', 'roast beef', 'pizza', 'mac and cheese', 'ziti', 'baked cheetos',\n",
    "        'totinos pizza', 'lean cuisine', 'brunswick stew', 'slaw', 'ranch'\n",
    "    ],\n",
    "    'dinner': [\n",
    "        'steak', 'ribs', 'baked chicken', 'chicken and rice', 'chicken breast', 'chicken thigh', 'chicken wing', 'chicken leg', 'chicken biscuit', 'chicken chorizo',\n",
    "        'chicken nuggets', 'omelet', 'egg salad', 'baked potato', 'salisbury steak', 'pot pie', 'ravioli', 'taco salad', 'chipotle', 'deluxe cheeseburger macaroni',\n",
    "        'cheeseburger', 'roast beef', 'pizza', 'mac and cheese', 'ziti', 'baked cheetos', 'totinos pizza', 'lean cuisine', 'salmon', 'shrimp', 'seafood', 'lasagna',\n",
    "        'vegetable lasagna', 'stuffing', 'brunswick stew', 'soup'\n",
    "    ],\n",
    "    'spicy': [\n",
    "        'spicy', 'sriracha', 'jalapeno', 'buffalo', 'hot', 'kimchi', 'chili'\n",
    "    ],\n",
    "    'healthy': [\n",
    "        'salad', 'spinach', 'asparagus', 'broccoli', 'kale', 'fruit', 'berries', 'berry', 'vegan', 'vegetarian', 'grilled', 'lactose free', 'skimmed', 'oatmeal',\n",
    "        'avocado', 'flaxseed', 'psyllium husks', 'cinnamon', 'extra virgin olive oil', 'olive oil', 'balsamic vinegar', 'lettuce mix', 'tomatoes', 'beets',\n",
    "        'carrots', 'cucumber', 'red bell pepper', 'brussel sprouts', 'sweet potato', 'faro', 'beet'\n",
    "    ],\n",
    "    'fast food': [\n",
    "        'arby', 'mcdonald', 'wendy', 'burger king', 'subway', 'taco bell', 'chick-fil-a', 'jimmy dean', 'powerade', 'gatorade', 'fritos', 'cheetos', 'totinos',\n",
    "        'lean cuisine', 'hamburger helper', 'red baron', 'outback steakhouse', 'trader joe', 'smoothie king', 'slim fast', 'ensure plus'\n",
    "    ],\n",
    "    'supplement': [\n",
    "        'protein', 'whey', 'creatine', 'bcaa', 'amino', 'pre workout', 'post workout', 'casein', 'glutamine', 'l-carnitine', 'l-arginine', 'l-tyrosine',\n",
    "        'mct oil', 'collagen', 'vitamin', 'mineral', 'fish oil', 'omega-3', 'probiotic', 'greens', 'fiber', 'electrolyte', 'meal replacement', 'oil'\n",
    "    ],\n",
    "    'medication': [\n",
    "        'insulin', 'metformin', 'glipizide', 'glyburide', 'sitagliptin', 'linagliptin', 'canagliflozin', 'dapagliflozin', 'empagliflozin', 'liraglutide',\n",
    "        'ibuprofen', 'aspirin', 'naproxen', 'acetaminophen', 'hydrochlorothiazide', 'lisinopril', 'atorvastatin', 'simvastatin', 'rosuvastatin', 'pravastatin'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def get_tags(logged_food, searched_food):\n",
    "    tags = set()\n",
    "    food_str = f\"{logged_food or ''} {searched_food or ''}\".lower()\n",
    "    # Tag assignment\n",
    "    for tag, keywords in tag_keywords.items():\n",
    "        for kw in keywords:\n",
    "            if kw in food_str:\n",
    "                tags.add(tag)\n",
    "                break\n",
    "    # Special rules\n",
    "    # If it's a drink, don't tag as entree/snack/dessert\n",
    "    if 'drink' in tags:\n",
    "        tags -= {'entree', 'snack', 'dessert'}\n",
    "    # If it's a dessert, don't tag as snack\n",
    "    if 'dessert' in tags:\n",
    "        tags -= {'snack'}\n",
    "    # If Vegetarian, remove vegan\n",
    "    if 'vegetarian' in tags and 'vegan' in tags:\n",
    "        tags.remove('vegan')\n",
    "    # If it's vegan, it's also vegetarian\n",
    "    if 'vegan' in tags:\n",
    "        tags.add('vegetarian')\n",
    "    # If it's meat, it's not vegan/vegetarian\n",
    "    if 'meat' in tags:\n",
    "        tags -= {'vegan', 'vegetarian'}\n",
    "    # If it's seafood, it's not meat\n",
    "    if 'seafood' in tags:\n",
    "        tags -= {'meat'}\n",
    "    # If it's breakfast, also consider as snack if not entree\n",
    "    if 'breakfast' in tags and 'entree' not in tags:\n",
    "        tags.add('snack')\n",
    "    return sorted(tags)\n",
    "\n",
    "# Process each entry\n",
    "for entry in data:\n",
    "    logged_food = entry.get('logged_food', '')\n",
    "    searched_food = entry.get('searched_food', '')\n",
    "    # Only process if there is a logged food\n",
    "    if logged_food or searched_food:\n",
    "        entry['tags'] = get_tags(logged_food, searched_food)\n",
    "        if not entry['tags']:\n",
    "            print(logged_food, searched_food)\n",
    "    else:\n",
    "        entry['tags'] = []\n",
    "        print(f\"missed logs {entry}\")\n",
    "\n",
    "# Save or print the updated data\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a61792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "output_dir = './Output/jsons/'\n",
    "\n",
    "input_file_path = os.path.join(output_dir, 'food_log_tagged.json')\n",
    "output_file_path = os.path.join(output_dir, 'food_log_tagged_grouped.json')\n",
    "\n",
    "# Load the data\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Remove empty dicts (some are at the end of your file)\n",
    "data = [row for row in data if row and isinstance(row, dict)]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop unwanted columns\n",
    "drop_cols = ['date', 'time', 'time_begin', 'time_end', 'amount', 'unit']\n",
    "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "# Fill NaN tags with empty list\n",
    "df['tags'] = df['tags'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "\n",
    "def apply_functions(x: pd.DataFrame):\n",
    "    return_series = pd.Series()\n",
    "\n",
    "    # sum the columns calorie total_carb dietary_fiber sugar protein total_fat\n",
    "    numeric_cols = ['calorie', 'total_carb', 'dietary_fiber', 'sugar', 'protein', 'total_fat']\n",
    "    for col in numeric_cols:\n",
    "        return_series[col] = x[col].sum()\n",
    "\n",
    "    # replace NaN with \"\" in x['logged_food']\n",
    "    x['logged_food'] = x['logged_food'].replace(np.nan, '', regex=True)\n",
    "    x['searched_food'] = x['searched_food'].replace(np.nan, '', regex=True)\n",
    "\n",
    "    # combine the food names\n",
    "    return_series['logged_food'] = ' and '.join(x['logged_food'])\n",
    "    return_series['searched_food'] = ' and '.join(x['searched_food'])\n",
    "\n",
    "    # combine the tags\n",
    "    return_series['tags'] = [item for sublist in x['tags'] for item in sublist]\n",
    "\n",
    "    # remove duplicates from tags\n",
    "    return_series['tags'] = list(set(return_series['tags']))\n",
    "\n",
    "    return return_series\n",
    "\n",
    "# Group by datetime and ID\n",
    "grouped = df.groupby(['datetime', 'ID'], as_index=False).apply(apply_functions, include_groups=False)\n",
    "grouped = grouped.reset_index(drop=True)\n",
    "\n",
    "# Write to JSON\n",
    "grouped.to_json(output_file_path, orient='records', indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1b46326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>logged_food</th>\n",
       "      <th>searched_food</th>\n",
       "      <th>calorie</th>\n",
       "      <th>total_carb</th>\n",
       "      <th>dietary_fiber</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>total_fat</th>\n",
       "      <th>ID</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-13T18:00:00</td>\n",
       "      <td>Berry Smoothie</td>\n",
       "      <td>Strawberry Smoothie</td>\n",
       "      <td>456.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>83.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>001</td>\n",
       "      <td>[drink, healthy, vegan, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13T20:30:00</td>\n",
       "      <td>Chicken Leg</td>\n",
       "      <td>chicken leg</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>001</td>\n",
       "      <td>[dinner, entree, lunch, meat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-13T20:30:00</td>\n",
       "      <td>Asparagus</td>\n",
       "      <td>Asparagus</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>001</td>\n",
       "      <td>[healthy, snack, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-14T07:10:00</td>\n",
       "      <td>Natrel Lactose Free 2 Percent</td>\n",
       "      <td>(Natrel) Lactose Free 2% Partly Skimmed Milk</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001</td>\n",
       "      <td>[breakfast, drink, healthy, snack, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-14T07:10:00</td>\n",
       "      <td>Standard Breakfast</td>\n",
       "      <td>(Kellogg's) Frosted Flakes, Cereal</td>\n",
       "      <td>110.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001</td>\n",
       "      <td>[breakfast, snack, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>2020-02-26T18:30:00</td>\n",
       "      <td>Lemonade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>016</td>\n",
       "      <td>[drink, vegan, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>2020-02-27T10:30:00</td>\n",
       "      <td>Standard breakfast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280.0</td>\n",
       "      <td>56.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>016</td>\n",
       "      <td>[breakfast, snack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>2020-02-27T11:30:00</td>\n",
       "      <td>Plain cheese pizza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>016</td>\n",
       "      <td>[dinner, entree, lunch, snack, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>2020-02-27T11:30:00</td>\n",
       "      <td>cooked black eyed peas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>016</td>\n",
       "      <td>[vegan, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>2020-02-28T08:00:00</td>\n",
       "      <td>Boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>654.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>016</td>\n",
       "      <td>[drink]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1364 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime                    logged_food  \\\n",
       "0     2020-02-13T18:00:00                 Berry Smoothie   \n",
       "1     2020-02-13T20:30:00                    Chicken Leg   \n",
       "2     2020-02-13T20:30:00                      Asparagus   \n",
       "3     2020-02-14T07:10:00  Natrel Lactose Free 2 Percent   \n",
       "4     2020-02-14T07:10:00             Standard Breakfast   \n",
       "...                   ...                            ...   \n",
       "1359  2020-02-26T18:30:00                       Lemonade   \n",
       "1360  2020-02-27T10:30:00             Standard breakfast   \n",
       "1361  2020-02-27T11:30:00             Plain cheese pizza   \n",
       "1362  2020-02-27T11:30:00         cooked black eyed peas   \n",
       "1363  2020-02-28T08:00:00                          Boost   \n",
       "\n",
       "                                     searched_food  calorie  total_carb  \\\n",
       "0                              Strawberry Smoothie    456.0        85.0   \n",
       "1                                      chicken leg    475.0         0.0   \n",
       "2                                        Asparagus     13.0         2.5   \n",
       "3     (Natrel) Lactose Free 2% Partly Skimmed Milk    120.0         9.0   \n",
       "4               (Kellogg's) Frosted Flakes, Cereal    110.0        26.0   \n",
       "...                                            ...      ...         ...   \n",
       "1359                                           NaN     99.0        26.0   \n",
       "1360                                           NaN    280.0        56.5   \n",
       "1361                                           NaN    452.0        57.0   \n",
       "1362                                           NaN    198.0        35.0   \n",
       "1363                                           NaN    654.0        82.0   \n",
       "\n",
       "      dietary_fiber  sugar  protein  total_fat   ID  \\\n",
       "0               1.7   83.0     16.0        3.3  001   \n",
       "1               0.0    0.0     62.0       23.0  001   \n",
       "2               1.2    0.8      1.4        0.1  001   \n",
       "3               NaN    8.0     12.0        NaN  001   \n",
       "4               NaN   10.0      1.0        NaN  001   \n",
       "...             ...    ...      ...        ...  ...   \n",
       "1359            0.0   25.0      0.2        0.1  016   \n",
       "1360            1.0   24.0      8.0        2.5  016   \n",
       "1361            3.9    6.1     19.0       16.0  016   \n",
       "1362           11.0    5.6     13.0        0.9  016   \n",
       "1363            5.6   40.0     26.0       26.0  016   \n",
       "\n",
       "                                                tags  \n",
       "0                [drink, healthy, vegan, vegetarian]  \n",
       "1                      [dinner, entree, lunch, meat]  \n",
       "2                       [healthy, snack, vegetarian]  \n",
       "3     [breakfast, drink, healthy, snack, vegetarian]  \n",
       "4                     [breakfast, snack, vegetarian]  \n",
       "...                                              ...  \n",
       "1359                      [drink, vegan, vegetarian]  \n",
       "1360                              [breakfast, snack]  \n",
       "1361      [dinner, entree, lunch, snack, vegetarian]  \n",
       "1362                             [vegan, vegetarian]  \n",
       "1363                                         [drink]  \n",
       "\n",
       "[1364 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "output_dir = './Output/jsons/'\n",
    "\n",
    "input_file_path = os.path.join(output_dir, 'food_log_tagged.json')\n",
    "output_file_path = os.path.join(output_dir, 'food_log_tagged_grouped.json')\n",
    "\n",
    "# Load the data\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Remove empty dicts (some are at the end of your file)\n",
    "data = [row for row in data if row and isinstance(row, dict)]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Drop unwanted columns\n",
    "drop_cols = ['date', 'time', 'time_begin', 'time_end', 'amount', 'unit']\n",
    "df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "# Fill NaN tags with empty list\n",
    "df['tags'] = df['tags'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efbfae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['logged_food'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbbff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "781960dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>ID</th>\n",
       "      <th>logged_food</th>\n",
       "      <th>searched_food</th>\n",
       "      <th>tags</th>\n",
       "      <th>calorie</th>\n",
       "      <th>total_carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-01T12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>apple pie</td>\n",
       "      <td>[fruit]</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-01T12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>banana</td>\n",
       "      <td>banana split</td>\n",
       "      <td>[happy]</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-01T13:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>carrot</td>\n",
       "      <td>carrot cake</td>\n",
       "      <td>[vegetable]</td>\n",
       "      <td>300</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  ID logged_food searched_food         tags  calorie  \\\n",
       "0  2023-10-01T12:00:00   1       apple     apple pie      [fruit]      100   \n",
       "1  2023-10-01T12:00:00   1      banana  banana split      [happy]      300   \n",
       "2  2023-10-01T13:00:00   2      carrot   carrot cake  [vegetable]      300   \n",
       "\n",
       "   total_carb  \n",
       "0          20  \n",
       "1          30  \n",
       "2          40  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sample dataframe to test pd.grouby.apply\n",
    "df = pd.DataFrame({\n",
    "    'datetime': ['2023-10-01T12:00:00', '2023-10-01T12:00:00', '2023-10-01T13:00:00'],\n",
    "    'ID': [1, 1, 2],\n",
    "    'logged_food': ['apple', 'banana', 'carrot'],\n",
    "    'searched_food': ['apple pie', 'banana split', 'carrot cake'],\n",
    "    'tags': [['fruit'], ['happy'], ['vegetable']],\n",
    "    'calorie': [100, 300, 300],\n",
    "    'total_carb': [20, 30, 40],\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ac7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fruit', 'happy']\n",
      "['vegetable']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>ID</th>\n",
       "      <th>calorie</th>\n",
       "      <th>total_carb</th>\n",
       "      <th>logged_food</th>\n",
       "      <th>searched_food</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-01T12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>apple and banana</td>\n",
       "      <td>apple pie and banana split</td>\n",
       "      <td>[fruit, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-01T13:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>40</td>\n",
       "      <td>carrot</td>\n",
       "      <td>carrot cake</td>\n",
       "      <td>[vegetable]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  ID  calorie  total_carb       logged_food  \\\n",
       "0  2023-10-01T12:00:00   1      400          50  apple and banana   \n",
       "1  2023-10-01T13:00:00   2      300          40            carrot   \n",
       "\n",
       "                searched_food            tags  \n",
       "0  apple pie and banana split  [fruit, happy]  \n",
       "1                 carrot cake     [vegetable]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make function to add numeric tags and append tags to one lisgt and combine food name using groupby.apply\n",
    "def function_apply (x):\n",
    "    return_series = pd.Series()\n",
    "\n",
    "    # sum the columns calorie total_carb dietary_fiber sugar protein total_fat\n",
    "    numeric_cols = ['calorie', 'total_carb']\n",
    "    for col in numeric_cols:\n",
    "        return_series[col] = x[col].sum()\n",
    "\n",
    "    # combine the food names\n",
    "    return_series['logged_food'] = ' and '.join(x['logged_food'])\n",
    "    return_series['searched_food'] = ' and '.join(x['searched_food'])\n",
    "    print([item for sublist in x['tags'] for item in sublist])\n",
    "\n",
    "    # combine the tags\n",
    "    return_series['tags'] = [item for sublist in x['tags'] for item in sublist]\n",
    "\n",
    "    return return_series\n",
    "\n",
    "# Group by datetime and ID\n",
    "grouped = df.groupby(['datetime', 'ID'], as_index=False).apply(function_apply, include_groups=False)\n",
    "grouped = grouped.reset_index(drop=True)\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891dbf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
